# Methods-of-collecting-and-processing-data-from-the-Internet

## Lesson 01
### Основы клиент-серверного взаимодействия. Парсинг API
1. Посмотреть документацию к API GitHub, разобраться как вывести список репозиториев для конкретного пользователя, сохранить JSON-вывод в файле *.json.
2. Изучить список открытых API. Найти среди них любое, требующее авторизацию (любого типа). Выполнить запросы к нему, пройдя авторизацию через curl, Postman, Python.Ответ сервера записать в файл (приложить скриншот для Postman и curl)

## Lesson 02
### Парсинг HTML. BeautifulSoup, MongoDB
Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы) с сайта superjob.ru и hh.ru. Приложение должно анализировать несколько страниц сайта(также вводим через input или аргументы). Получившийся список должен содержать в себе минимум:

- Наименование вакансии
- Предлагаемую зарплату (отдельно мин. и и отдельно макс.)
- Ссылку на саму вакансию
- Сайт откуда собрана вакансия

## Lesson 03
### Парсинг HTML. BS, SQLAlchemy
1. Развернуть у себя на компьютере/виртуальной машине/хостинге MongoDB и реализовать функцию, записывающую собранные вакансии в созданную БД
2. Написать функцию, которая производит поиск и выводит на экран вакансии с заработной платой больше введенной суммы
3. \* Написать функцию, которая будет добавлять в вашу базу данных только новые вакансии с сайта

## Lesson 04
### Парсинг HTML. XPath
Написать приложение, которое собирает основные новости с сайтов mail.ru, lenta.ru.
Для парсинга использовать xpath. Структура данных должна содержать:
- название источника,
- наименование новости,
- ссылку на новость,
- дата публикации

## Lesson 05
## Scrapy
1. Доработать паука в имеющемся проекте, чтобы он формировал item по структуре:
- Наименование вакансии
- Зарплата от
- Зарплата до
- Ссылку на саму вакансию
- Сайт откуда собрана вакансия  

И складывал все записи в БД(любую)

2. Создать в имеющемся проекте второго паука по сбору вакансий с сайта superjob. Паука должен формировать item'ы по аналогичной структуре и складывать данные также в БД
3. \* Измерить скорость сбора вакансий в проекте и сравнить ее с проектом, выполненном с использованием BS+requests

